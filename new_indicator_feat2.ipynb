{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bba66d00-cc4e-4075-9687-1e6da40b4d37",
      "metadata": {
        "id": "bba66d00-cc4e-4075-9687-1e6da40b4d37"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0a609494-f725-4749-9a47-e15592616b94",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:18:09.667959Z",
          "iopub.status.busy": "2023-09-06T06:18:09.667594Z",
          "iopub.status.idle": "2023-09-06T06:18:13.554794Z",
          "shell.execute_reply": "2023-09-06T06:18:13.553977Z",
          "shell.execute_reply.started": "2023-09-06T06:18:09.667934Z"
        },
        "id": "0a609494-f725-4749-9a47-e15592616b94",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "495edb84-1e54-4858-a999-bec5a0f2fb96",
      "metadata": {
        "id": "495edb84-1e54-4858-a999-bec5a0f2fb96"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "73b1d934-7ad5-4881-b589-d45392510161",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:18:13.556679Z",
          "iopub.status.busy": "2023-09-06T06:18:13.556157Z",
          "iopub.status.idle": "2023-09-06T06:18:13.945247Z",
          "shell.execute_reply": "2023-09-06T06:18:13.944482Z",
          "shell.execute_reply.started": "2023-09-06T06:18:13.556655Z"
        },
        "id": "73b1d934-7ad5-4881-b589-d45392510161",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_parquet('data/train.parquet')\n",
        "test_df = pd.read_parquet('data/test.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "273ab3f4-5b7c-4f2f-8ee0-4ef3835eae67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "execution": {
          "iopub.execute_input": "2023-09-06T06:18:13.961513Z",
          "iopub.status.busy": "2023-09-06T06:18:13.961271Z",
          "iopub.status.idle": "2023-09-06T06:18:13.982369Z",
          "shell.execute_reply": "2023-09-06T06:18:13.981811Z",
          "shell.execute_reply.started": "2023-09-06T06:18:13.961493Z"
        },
        "id": "273ab3f4-5b7c-4f2f-8ee0-4ef3835eae67",
        "outputId": "941cdd31-06b8-4489-ba27-d63bda370fc3",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>rko_start_months</th>\n",
              "      <th>max_end_fact_fin_deals</th>\n",
              "      <th>max_end_plan_non_fin_deals</th>\n",
              "      <th>max_start_fin_deals</th>\n",
              "      <th>max_start_non_fin_deals</th>\n",
              "      <th>min_end_fact_fin_deals</th>\n",
              "      <th>min_end_plan_non_fin_deals</th>\n",
              "      <th>min_start_fin_deals</th>\n",
              "      <th>min_start_non_fin_deals</th>\n",
              "      <th>...</th>\n",
              "      <th>cnt_days_cred_g_oper_3m</th>\n",
              "      <th>sum_deb_h_oper_3m</th>\n",
              "      <th>cnt_deb_h_oper_3m</th>\n",
              "      <th>cnt_days_deb_h_oper_3m</th>\n",
              "      <th>sum_cred_h_oper_3m</th>\n",
              "      <th>cnt_cred_h_oper_3m</th>\n",
              "      <th>cnt_days_cred_h_oper_3m</th>\n",
              "      <th>target_1</th>\n",
              "      <th>target_2</th>\n",
              "      <th>total_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>48.871217</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.064993</td>\n",
              "      <td>33196.020871</td>\n",
              "      <td>1.229488</td>\n",
              "      <td>0.396969</td>\n",
              "      <td>323523.957625</td>\n",
              "      <td>12.420855</td>\n",
              "      <td>9.069157</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>19.530576</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.270542</td>\n",
              "      <td>33195.488147</td>\n",
              "      <td>1.229488</td>\n",
              "      <td>-0.137339</td>\n",
              "      <td>145641.572203</td>\n",
              "      <td>2.124925</td>\n",
              "      <td>2.069157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>9.706201</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>23.431839</td>\n",
              "      <td>265071.236918</td>\n",
              "      <td>4.229488</td>\n",
              "      <td>3.595162</td>\n",
              "      <td>125727.062161</td>\n",
              "      <td>0.999583</td>\n",
              "      <td>1.069157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>92.569902</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.990581</td>\n",
              "      <td>495094.276542</td>\n",
              "      <td>9.229488</td>\n",
              "      <td>8.582252</td>\n",
              "      <td>370392.322955</td>\n",
              "      <td>3.066714</td>\n",
              "      <td>3.069157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>26.538856</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.393927</td>\n",
              "      <td>33196.317418</td>\n",
              "      <td>1.229488</td>\n",
              "      <td>0.276606</td>\n",
              "      <td>125726.775788</td>\n",
              "      <td>1.219935</td>\n",
              "      <td>1.069157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 103 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  rko_start_months  max_end_fact_fin_deals  max_end_plan_non_fin_deals  \\\n",
              "0   0         48.871217                     NaN                         NaN   \n",
              "1   1         19.530576                     NaN                         NaN   \n",
              "2   2          9.706201                     NaN                         NaN   \n",
              "3   3         92.569902                     NaN                         NaN   \n",
              "4   4         26.538856                     NaN                         NaN   \n",
              "\n",
              "   max_start_fin_deals  max_start_non_fin_deals  min_end_fact_fin_deals  \\\n",
              "0                  NaN                      NaN                     NaN   \n",
              "1                  NaN                      NaN                     NaN   \n",
              "2                  NaN                      NaN                     NaN   \n",
              "3                  NaN                      NaN                     NaN   \n",
              "4                  NaN                      NaN                     NaN   \n",
              "\n",
              "   min_end_plan_non_fin_deals  min_start_fin_deals  min_start_non_fin_deals  \\\n",
              "0                         NaN                  NaN                      NaN   \n",
              "1                         NaN                  NaN                      NaN   \n",
              "2                         NaN                  NaN                      NaN   \n",
              "3                         NaN                  NaN                      NaN   \n",
              "4                         NaN                  NaN                      NaN   \n",
              "\n",
              "   ...  cnt_days_cred_g_oper_3m  sum_deb_h_oper_3m  cnt_deb_h_oper_3m  \\\n",
              "0  ...                 0.064993       33196.020871           1.229488   \n",
              "1  ...                 0.270542       33195.488147           1.229488   \n",
              "2  ...                23.431839      265071.236918           4.229488   \n",
              "3  ...                 0.990581      495094.276542           9.229488   \n",
              "4  ...                 0.393927       33196.317418           1.229488   \n",
              "\n",
              "   cnt_days_deb_h_oper_3m sum_cred_h_oper_3m cnt_cred_h_oper_3m  \\\n",
              "0                0.396969      323523.957625          12.420855   \n",
              "1               -0.137339      145641.572203           2.124925   \n",
              "2                3.595162      125727.062161           0.999583   \n",
              "3                8.582252      370392.322955           3.066714   \n",
              "4                0.276606      125726.775788           1.219935   \n",
              "\n",
              "  cnt_days_cred_h_oper_3m target_1  target_2  total_target  \n",
              "0                9.069157        1         1             1  \n",
              "1                2.069157        0         0             0  \n",
              "2                1.069157        0         0             0  \n",
              "3                3.069157        0         0             0  \n",
              "4                1.069157        0         0             0  \n",
              "\n",
              "[5 rows x 103 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ee0a3c20-70c9-4359-a267-722fcab498b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "execution": {
          "iopub.execute_input": "2023-09-06T06:18:13.983350Z",
          "iopub.status.busy": "2023-09-06T06:18:13.983106Z",
          "iopub.status.idle": "2023-09-06T06:18:13.999637Z",
          "shell.execute_reply": "2023-09-06T06:18:13.999149Z",
          "shell.execute_reply.started": "2023-09-06T06:18:13.983331Z"
        },
        "id": "ee0a3c20-70c9-4359-a267-722fcab498b2",
        "outputId": "2a4267c1-23d8-486e-b496-20f26a8b1061",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>rko_start_months</th>\n",
              "      <th>max_end_fact_fin_deals</th>\n",
              "      <th>max_end_plan_non_fin_deals</th>\n",
              "      <th>max_start_fin_deals</th>\n",
              "      <th>max_start_non_fin_deals</th>\n",
              "      <th>min_end_fact_fin_deals</th>\n",
              "      <th>min_end_plan_non_fin_deals</th>\n",
              "      <th>min_start_fin_deals</th>\n",
              "      <th>min_start_non_fin_deals</th>\n",
              "      <th>...</th>\n",
              "      <th>cnt_days_deb_g_oper_3m</th>\n",
              "      <th>sum_cred_g_oper_3m</th>\n",
              "      <th>cnt_cred_g_oper_3m</th>\n",
              "      <th>cnt_days_cred_g_oper_3m</th>\n",
              "      <th>sum_deb_h_oper_3m</th>\n",
              "      <th>cnt_deb_h_oper_3m</th>\n",
              "      <th>cnt_days_deb_h_oper_3m</th>\n",
              "      <th>sum_cred_h_oper_3m</th>\n",
              "      <th>cnt_cred_h_oper_3m</th>\n",
              "      <th>cnt_days_cred_h_oper_3m</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360000</td>\n",
              "      <td>61.061808</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.531871</td>\n",
              "      <td>51005.755087</td>\n",
              "      <td>4.275226</td>\n",
              "      <td>4.257042</td>\n",
              "      <td>33195.968822</td>\n",
              "      <td>1.229488</td>\n",
              "      <td>0.359263</td>\n",
              "      <td>301442.064297</td>\n",
              "      <td>7.049883</td>\n",
              "      <td>7.069157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360001</td>\n",
              "      <td>16.803743</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.531871</td>\n",
              "      <td>11.888083</td>\n",
              "      <td>0.275226</td>\n",
              "      <td>0.257042</td>\n",
              "      <td>33195.968822</td>\n",
              "      <td>1.229488</td>\n",
              "      <td>0.359263</td>\n",
              "      <td>125727.663401</td>\n",
              "      <td>1.049883</td>\n",
              "      <td>1.069157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360002</td>\n",
              "      <td>15.448904</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.531871</td>\n",
              "      <td>11.888083</td>\n",
              "      <td>0.275226</td>\n",
              "      <td>0.257042</td>\n",
              "      <td>33195.968822</td>\n",
              "      <td>1.229488</td>\n",
              "      <td>0.359263</td>\n",
              "      <td>125727.663401</td>\n",
              "      <td>1.049883</td>\n",
              "      <td>1.069157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360003</td>\n",
              "      <td>11.287614</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.531871</td>\n",
              "      <td>11.888083</td>\n",
              "      <td>0.275226</td>\n",
              "      <td>0.257042</td>\n",
              "      <td>33195.968822</td>\n",
              "      <td>1.229488</td>\n",
              "      <td>0.359263</td>\n",
              "      <td>125727.663401</td>\n",
              "      <td>1.049883</td>\n",
              "      <td>1.069157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>360004</td>\n",
              "      <td>7.997291</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.531871</td>\n",
              "      <td>11.888083</td>\n",
              "      <td>0.275226</td>\n",
              "      <td>0.257042</td>\n",
              "      <td>135758.248681</td>\n",
              "      <td>2.229488</td>\n",
              "      <td>1.359263</td>\n",
              "      <td>126742.064297</td>\n",
              "      <td>2.049883</td>\n",
              "      <td>2.069157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  rko_start_months  max_end_fact_fin_deals  \\\n",
              "0  360000         61.061808                     NaN   \n",
              "1  360001         16.803743                     NaN   \n",
              "2  360002         15.448904                     NaN   \n",
              "3  360003         11.287614                     NaN   \n",
              "4  360004          7.997291                     NaN   \n",
              "\n",
              "   max_end_plan_non_fin_deals  max_start_fin_deals  max_start_non_fin_deals  \\\n",
              "0                         NaN                  NaN                      NaN   \n",
              "1                         NaN                  NaN                      NaN   \n",
              "2                         NaN                  NaN                      NaN   \n",
              "3                         NaN                  NaN                      NaN   \n",
              "4                         NaN                  NaN                      NaN   \n",
              "\n",
              "   min_end_fact_fin_deals  min_end_plan_non_fin_deals  min_start_fin_deals  \\\n",
              "0                     NaN                         NaN                  NaN   \n",
              "1                     NaN                         NaN                  NaN   \n",
              "2                     NaN                         NaN                  NaN   \n",
              "3                     NaN                         NaN                  NaN   \n",
              "4                     NaN                         NaN                  NaN   \n",
              "\n",
              "   min_start_non_fin_deals  ...  cnt_days_deb_g_oper_3m  sum_cred_g_oper_3m  \\\n",
              "0                      NaN  ...                0.531871        51005.755087   \n",
              "1                      NaN  ...                0.531871           11.888083   \n",
              "2                      NaN  ...                0.531871           11.888083   \n",
              "3                      NaN  ...                0.531871           11.888083   \n",
              "4                      NaN  ...                0.531871           11.888083   \n",
              "\n",
              "   cnt_cred_g_oper_3m  cnt_days_cred_g_oper_3m sum_deb_h_oper_3m  \\\n",
              "0            4.275226                 4.257042      33195.968822   \n",
              "1            0.275226                 0.257042      33195.968822   \n",
              "2            0.275226                 0.257042      33195.968822   \n",
              "3            0.275226                 0.257042      33195.968822   \n",
              "4            0.275226                 0.257042     135758.248681   \n",
              "\n",
              "  cnt_deb_h_oper_3m cnt_days_deb_h_oper_3m sum_cred_h_oper_3m  \\\n",
              "0          1.229488               0.359263      301442.064297   \n",
              "1          1.229488               0.359263      125727.663401   \n",
              "2          1.229488               0.359263      125727.663401   \n",
              "3          1.229488               0.359263      125727.663401   \n",
              "4          2.229488               1.359263      126742.064297   \n",
              "\n",
              "   cnt_cred_h_oper_3m  cnt_days_cred_h_oper_3m  \n",
              "0            7.049883                 7.069157  \n",
              "1            1.049883                 1.069157  \n",
              "2            1.049883                 1.069157  \n",
              "3            1.049883                 1.069157  \n",
              "4            2.049883                 2.069157  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67b32f0c-5d70-4435-a8d5-7d41b4c6826b",
      "metadata": {
        "id": "67b32f0c-5d70-4435-a8d5-7d41b4c6826b"
      },
      "source": [
        "## Обработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65425a43-b496-4aae-9cbf-217d7ba50047",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-30T11:51:15.377327Z",
          "iopub.status.busy": "2023-08-30T11:51:15.376738Z",
          "iopub.status.idle": "2023-08-30T11:51:15.417269Z",
          "shell.execute_reply": "2023-08-30T11:51:15.416369Z",
          "shell.execute_reply.started": "2023-08-30T11:51:15.377282Z"
        },
        "id": "65425a43-b496-4aae-9cbf-217d7ba50047",
        "tags": []
      },
      "source": [
        "Для базовой модели отбросим отдельные таргеты и будем использовать только total_target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ae050d6d-b793-48c1-b487-75ff8acb9ff2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:18:14.000541Z",
          "iopub.status.busy": "2023-09-06T06:18:14.000311Z",
          "iopub.status.idle": "2023-09-06T06:18:14.122317Z",
          "shell.execute_reply": "2023-09-06T06:18:14.121468Z",
          "shell.execute_reply.started": "2023-09-06T06:18:14.000524Z"
        },
        "id": "ae050d6d-b793-48c1-b487-75ff8acb9ff2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_df.drop([\"id\", \"target_1\", \"target_2\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1bdd05e-f785-4d72-9ebb-012c481804d0",
      "metadata": {
        "id": "d1bdd05e-f785-4d72-9ebb-012c481804d0"
      },
      "source": [
        "Преобразуем тип категориальных признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ff73f27-969f-4c12-af6d-5e745b107ef5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:18:14.445065Z",
          "iopub.status.busy": "2023-09-06T06:18:14.444630Z",
          "iopub.status.idle": "2023-09-06T06:18:14.448491Z",
          "shell.execute_reply": "2023-09-06T06:18:14.447886Z",
          "shell.execute_reply.started": "2023-09-06T06:18:14.445026Z"
        },
        "id": "4ff73f27-969f-4c12-af6d-5e745b107ef5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "cat_cols = [\n",
        "    'channel_code', 'city', 'city_type',\n",
        "    'index_city_code', 'ogrn_month', 'ogrn_year',\n",
        "    'branch_code', 'okved', 'segment'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c07db730-5abe-43e0-a05b-4a266e572cb2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:18:14.462578Z",
          "iopub.status.busy": "2023-09-06T06:18:14.462288Z",
          "iopub.status.idle": "2023-09-06T06:18:14.704172Z",
          "shell.execute_reply": "2023-09-06T06:18:14.703182Z",
          "shell.execute_reply.started": "2023-09-06T06:18:14.462550Z"
        },
        "id": "c07db730-5abe-43e0-a05b-4a266e572cb2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_df[cat_cols] = train_df[cat_cols].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "848a5194-66b9-4a1d-a5af-b97b62054125",
      "metadata": {
        "id": "848a5194-66b9-4a1d-a5af-b97b62054125"
      },
      "source": [
        "## Разбиение на train, validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test,y_train, y_test = train_test_split(train_df.drop('total_target', axis = 1), train_df.total_target, random_state=30, test_size= 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tuned_params = {**study.best_params}\n",
        "tuned_params = {'lambda_l1': 0.5349409254631267,\n",
        " 'lambda_l2': 0.49856117774439324,\n",
        " 'num_leaves': 512,\n",
        " 'feature_fraction': 0.42939817341414027,\n",
        " 'bagging_fraction': 0.5006754316465933,\n",
        " 'min_child_samples': 30,\n",
        " 'learning_rate': 0.03166155472455522,\n",
        " 'n_estimators': 410}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df[cat_cols] = test_df[cat_cols].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import StratifiedGroupKFold\n",
        "# from sklearn.metrics import roc_auc_score, classification_report\n",
        "# import xgboost as xgb\n",
        "# import numpy as np\n",
        "# def my_cross_valid(X, y):\n",
        "#     kf = StratifiedGroupKFold(n_splits=10)\n",
        "#     models = []\n",
        "#     metrics = []\n",
        "#     X = np.array(X)\n",
        "#     y = np.array(y)\n",
        "#     counter = 0\n",
        "#     for train_index, test_index in kf.split(X, y):\n",
        "#         print(counter)\n",
        "#         counter += 1\n",
        "  \n",
        "#         X_train, X_test = X[train_index], X[test_index]\n",
        "#         y_train, y_test = y[train_index], y[test_index]\n",
        "#         # positive_examples = np.sum(y_train)\n",
        "#         # negative_examples = len(y_train) - np.sum(y_train)\n",
        "#         # scale_pos_weight = (negative_examples)/(positive_examples)\n",
        "#         model = LGBMClassifier(**tuned_params)\n",
        "#         model.fit(X_train, y_train)\n",
        "\n",
        "#         # print('score:', roc_auc_score(y_test, predicts))\n",
        "#         models.append(model)\n",
        "#         metrics.append(metrics)\n",
        "#     return models, metrics\n",
        "# models, metrics = my_cross_valid(train_df.drop(['total_target'], axis = 1), train_df.total_target)\n",
        "# predicts = []\n",
        "# probas = np.zeros(len(X_test))\n",
        "# for model in models:\n",
        "#     print(np.array(model.predict_proba(X_test)).shape)\n",
        "#     probas += model.predict_proba(X_test)[:,1] * 0.1\n",
        "    \n",
        "#     predicts.append(model.predict(X_test))\n",
        "\n",
        "\n",
        "\n",
        "# predicts = np.round(np.sum(np.array(predicts).T, axis = 1)/10)\n",
        "# print(classification_report(y_test, predicts), roc_auc_score(y_test, probas))\n",
        "# probas\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8f7d39e-c56b-4700-a0dc-909888e1b254",
      "metadata": {
        "id": "f8f7d39e-c56b-4700-a0dc-909888e1b254"
      },
      "source": [
        "## Обучение базовой модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022f3ef3-813d-4df1-b1fd-7965a9e4b203",
      "metadata": {
        "id": "022f3ef3-813d-4df1-b1fd-7965a9e4b203"
      },
      "source": [
        "В качестве базовой модели возьмем LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mean_opp_c_1m = train_df[train_df['total_target'] == 1]['sum_c_oper_1m'].mean()\n",
        "\n",
        "train_df['Ind_sum_c_oper_1m'] = train_df['sum_c_oper_1m'].apply(lambda x: 1 if x < mean_opp_c_1m else 0)\n",
        "test_df['Ind_sum_c_oper_1m'] = test_df['sum_c_oper_1m'].apply(lambda x: 1 if x < mean_opp_c_1m else 0)\n",
        "\n",
        "# model = LGBMClassifier(num_leaves=num_leaves)\n",
        "# model.fit(X_train.drop('total_target', axis = 1), y_train)\n",
        "# roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mean_deb_sum_g_1m = train_df[train_df['total_target'] == 1]['sum_deb_g_oper_1m'].mean()\n",
        "\n",
        "train_df['Ind_sum_g_oper_1m'] = train_df['sum_deb_g_oper_1m'].apply(lambda x: 1 if x < mean_deb_sum_g_1m else 0)\n",
        "test_df['Ind_sum_g_oper_1m'] = test_df['sum_deb_g_oper_1m'].apply(lambda x: 1 if x < mean_deb_sum_g_1m else 0)\n",
        "\n",
        "# model = LGBMClassifier(num_leaves=num_leaves)\n",
        "# model.fit(X_train.drop(['total_target'], axis = 1), y_train)\n",
        "# roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mean_deb_sum_g_1m = train_df[train_df['total_target'] == 1]['sum_deb_f_oper_1m'].mean()\n",
        "\n",
        "train_df['Ind_sum_f_oper_1m'] = train_df['sum_deb_f_oper_1m'].apply(lambda x: 1 if x < mean_deb_sum_g_1m else 0)\n",
        "test_df['Ind_sum_f_oper_1m'] = test_df['sum_deb_f_oper_1m'].apply(lambda x: 1 if x < mean_deb_sum_g_1m else 0)\n",
        "\n",
        "# model = LGBMClassifier(num_leaves = num_leaves)\n",
        "# model.fit(X_train.drop(['total_target'], axis = 1), y_train)\n",
        "# roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "sum_deb_sum_e_3m = train_df[train_df['total_target'] == 1]['sum_deb_e_oper_3m'].mean()\n",
        "train_df['Ind_sum_e_oper_3m'] = train_df['sum_deb_e_oper_3m'].apply(lambda x: 1 if x < sum_deb_sum_e_3m else 0)\n",
        "test_df['Ind_sum_e_oper_3m'] = test_df['sum_deb_e_oper_3m'].apply(lambda x: 1 if x < sum_deb_sum_e_3m else 0)\n",
        "\n",
        "# model = LGBMClassifier(num_leaves = num_leaves)\n",
        "# model.fit(X_train.drop(['total_target'], axis = 1), y_train)\n",
        "# roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "sum_deb_sum_g_3m = train_df[train_df['total_target'] == 1]['sum_deb_g_oper_3m'].mean()\n",
        "\n",
        "train_df['Ind_sum_g_oper_3m'] = train_df['sum_deb_g_oper_3m'].apply(lambda x: 1 if x < sum_deb_sum_g_3m else 0)\n",
        "test_df['Ind_sum_g_oper_3m'] = test_df['sum_deb_g_oper_3m'].apply(lambda x: 1 if x < sum_deb_sum_g_3m else 0)\n",
        "\n",
        "# model = LGBMClassifier(num_leaves = num_leaves)\n",
        "# model.fit(X_train.drop(['total_target'], axis = 1), y_train)\n",
        "# roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "cnt_c_oper_3m = train_df[train_df['total_target'] == 1]['cnt_c_oper_3m'].mean()\n",
        "\n",
        "train_df['Ind_cnt_c_oper_3m'] = train_df['cnt_c_oper_3m'].apply(lambda x: 1 if x < cnt_c_oper_3m else 0)\n",
        "test_df['Ind_cnt_c_oper_3m'] = test_df['cnt_c_oper_3m'].apply(lambda x: 1 if x < cnt_c_oper_3m else 0)\n",
        "\n",
        "# model = LGBMClassifier(num_leaves = num_leaves)\n",
        "# model.fit(X_train.drop(['total_target'], axis = 1), y_train)\n",
        "# roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "cnt_deb_d_oper_1m = train_df[train_df['total_target'] == 1]['cnt_deb_d_oper_1m'].mean()\n",
        "\n",
        "train_df['Ind_cnt_d_oper_1m'] = train_df['cnt_deb_d_oper_3m'].apply(lambda x: 1 if x < cnt_deb_d_oper_1m else 0)\n",
        "test_df['Ind_cnt_d_oper_1m'] = test_df['cnt_deb_d_oper_3m'].apply(lambda x: 1 if x < cnt_deb_d_oper_1m  else 0)\n",
        "\n",
        "# model = LGBMClassifier(num_leaves = num_leaves)\n",
        "# model.fit(X_train.drop(['total_target'], axis = 1), y_train)\n",
        "# roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['max_end_fact_fin_deals_isna'] = train_df['max_end_fact_fin_deals'].isna()\n",
        "test_df['max_end_fact_fin_deals_isna'] = test_df['max_end_fact_fin_deals'].isna()\n",
        "\n",
        "train_df['max_end_plan_non_fin_deals_isna'] = train_df['max_end_plan_non_fin_deals'].isna()\n",
        "test_df['max_end_plan_non_fin_deals_isna'] = test_df['max_end_plan_non_fin_deals'].isna()\n",
        "\n",
        "train_df['max_start_fin_deals_isna'] = train_df['max_start_fin_deals'].isna()\n",
        "test_df['max_start_fin_deals_isna'] = test_df['max_start_fin_deals'].isna()\n",
        "\n",
        "train_df['max_start_non_fin_deals_isna'] = train_df['max_start_non_fin_deals'].isna()\n",
        "test_df['max_start_non_fin_deals_isna'] = test_df['max_start_non_fin_deals'].isna()\n",
        "\n",
        "train_df['min_end_fact_fin_deals_isna'] = train_df['min_end_fact_fin_deals'].isna()\n",
        "test_df['min_end_fact_fin_deals_isna'] = test_df['min_end_fact_fin_deals'].isna()\n",
        "\n",
        "train_df['min_end_plan_non_fin_deals_isna'] = train_df['min_end_plan_non_fin_deals'].isna()\n",
        "test_df['min_end_plan_non_fin_deals_isna'] = test_df['min_end_plan_non_fin_deals'].isna()\n",
        "\n",
        "train_df['min_start_fin_deals_isna'] = train_df['min_start_fin_deals'].isna()\n",
        "test_df['min_start_fin_deals_isna'] = test_df['min_start_fin_deals'].isna()\n",
        "\n",
        "train_df['min_start_non_fin_deals_isna'] = train_df['min_start_non_fin_deals'].isna()\n",
        "test_df['min_start_non_fin_deals_isna'] = test_df['min_start_non_fin_deals'].isna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "def LightGBM(params, X_train_adv, X_valid_adv, y_train_adv, y_valid_adv):\n",
        "    # Set data\n",
        "    lgb_train = lgb.Dataset(X_train_adv, y_train_adv)\n",
        "    lgb_valid = lgb.Dataset(X_valid_adv, y_valid_adv, reference = lgb_train)\n",
        "    # Training\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        lgb_train,\n",
        "        valid_sets = [lgb_train, lgb_valid],\n",
        "        num_boost_round = 2000,\n",
        "\n",
        "\n",
        "    )\n",
        "    # Prediction\n",
        "    y_pred = model.predict(X_valid_adv, num_iteration = model.best_iteration)\n",
        "    # Evaluation\n",
        "    ROC_AUC_Score = roc_auc_score(y_valid_adv,y_pred)\n",
        "    print('ROC AUC Score of LightGBM =', ROC_AUC_Score)\n",
        "    return ROC_AUC_Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'task': 'train',\n",
        "        'objective': 'binary',\n",
        "        'verbose': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'seed': 42,\n",
        "        'metric': 'AUC',\n",
        "        'is_unbalance': True,\n",
        "        # 'device': 'gpu',\n",
        "        'gpu_platform_id': 0,\n",
        "        'gpu_device_id': 0,\n",
        "        'num_threads': 4,\n",
        "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
        "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 1000),\n",
        "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
        "                                                  0.8),\n",
        "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
        "                                                  0.8),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 25, 50),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n",
        "    }\n",
        "\n",
        "    return LightGBM(params, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test,y_train, y_test = train_test_split(train_df.drop('total_target', axis = 1), train_df.total_target, random_state=30, test_size= 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-30 20:50:28,486] A new study created in memory with name: no-name-e4e16f19-f050-4961-a2da-3b9e1d56f666\n",
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 20:53:37,224] Trial 0 finished with value: 0.8982300774318328 and parameters: {'lambda_l1': 0.22772048646396836, 'lambda_l2': 0.8076291868832455, 'num_leaves': 733, 'feature_fraction': 0.6394633936788147, 'bagging_fraction': 0.46240745617697465, 'min_child_samples': 29, 'learning_rate': 1.7073967431528103e-05, 'n_estimators': 880}. Best is trial 0 with value: 0.8982300774318328.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.8982300774318328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 20:53:56,895] Trial 1 finished with value: 0.8687531204088663 and parameters: {'lambda_l1': 0.374635990894187, 'lambda_l2': 0.4738849906332293, 'num_leaves': 22, 'feature_fraction': 0.7879639408647978, 'bagging_fraction': 0.7329770563201687, 'min_child_samples': 30, 'learning_rate': 5.3370327626039544e-05, 'n_estimators': 265}. Best is trial 0 with value: 0.8982300774318328.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.8687531204088663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 20:55:03,485] Trial 2 finished with value: 0.8970318983561765 and parameters: {'lambda_l1': 0.1951285787906072, 'lambda_l2': 0.31677061966581566, 'num_leaves': 433, 'feature_fraction': 0.5164916560792168, 'bagging_fraction': 0.6447411578889518, 'min_child_samples': 28, 'learning_rate': 0.00014742753159914678, 'n_estimators': 430}. Best is trial 0 with value: 0.8982300774318328.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.8970318983561765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 20:55:37,083] Trial 3 finished with value: 0.8969164540898132 and parameters: {'lambda_l1': 0.2723964016251464, 'lambda_l2': 0.5613688105864871, 'num_leaves': 201, 'feature_fraction': 0.6056937753654447, 'bagging_fraction': 0.636965827544817, 'min_child_samples': 26, 'learning_rate': 0.0026926469100861782, 'n_estimators': 253}. Best is trial 0 with value: 0.8982300774318328.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.8969164540898132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 20:57:55,320] Trial 4 finished with value: 0.9133541275273855 and parameters: {'lambda_l1': 0.11536524569461262, 'lambda_l2': 0.8043904692207977, 'num_leaves': 966, 'feature_fraction': 0.7233589392465845, 'bagging_fraction': 0.5218455076693483, 'min_child_samples': 27, 'learning_rate': 0.005456725485601475, 'n_estimators': 496}. Best is trial 4 with value: 0.9133541275273855.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9133541275273855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 20:58:47,531] Trial 5 finished with value: 0.8766392686822664 and parameters: {'lambda_l1': 0.13075372538452143, 'lambda_l2': 0.296837562927497, 'num_leaves': 36, 'feature_fraction': 0.7637281608315128, 'bagging_fraction': 0.5035119926400068, 'min_child_samples': 42, 'learning_rate': 0.00017654048052495074, 'n_estimators': 568}. Best is trial 4 with value: 0.9133541275273855.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.8766392686822664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:02:41,911] Trial 6 finished with value: 0.9119409283333936 and parameters: {'lambda_l1': 0.33242539149739436, 'lambda_l2': 0.15010528365193862, 'num_leaves': 970, 'feature_fraction': 0.7100531293444459, 'bagging_fraction': 0.7757995766256757, 'min_child_samples': 48, 'learning_rate': 0.002463768595899745, 'n_estimators': 930}. Best is trial 4 with value: 0.9133541275273855.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9119409283333936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:03:12,834] Trial 7 finished with value: 0.9003104711874578 and parameters: {'lambda_l1': 0.12146280526491705, 'lambda_l2': 0.15382083992151838, 'num_leaves': 47, 'feature_fraction': 0.5301321323053058, 'bagging_fraction': 0.5554709158757929, 'min_child_samples': 32, 'learning_rate': 0.02065142557895925, 'n_estimators': 421}. Best is trial 4 with value: 0.9133541275273855.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9003104711874578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:03:49,010] Trial 8 finished with value: 0.9019719095430984 and parameters: {'lambda_l1': 0.18538716004172406, 'lambda_l2': 0.3295062618725358, 'num_leaves': 142, 'feature_fraction': 0.7208787923016159, 'bagging_fraction': 0.42982025747190833, 'min_child_samples': 50, 'learning_rate': 0.012273800987852962, 'n_estimators': 279}. Best is trial 4 with value: 0.9133541275273855.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9019719095430984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:04:32,926] Trial 9 finished with value: 0.8984456177291467 and parameters: {'lambda_l1': 0.10122072389412669, 'lambda_l2': 0.5999954539627869, 'num_leaves': 708, 'feature_fraction': 0.691602867216395, 'bagging_fraction': 0.7085081386743783, 'min_child_samples': 26, 'learning_rate': 0.00027155819552829395, 'n_estimators': 204}. Best is trial 4 with value: 0.9133541275273855.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.8984456177291467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:06:24,457] Trial 10 finished with value: 0.9175476419808126 and parameters: {'lambda_l1': 0.6560198577192052, 'lambda_l2': 0.776578232276206, 'num_leaves': 970, 'feature_fraction': 0.4071847502459278, 'bagging_fraction': 0.549073534840812, 'min_child_samples': 36, 'learning_rate': 0.06903717055434683, 'n_estimators': 709}. Best is trial 10 with value: 0.9175476419808126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9175476419808126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:07:52,646] Trial 11 finished with value: 0.9166019388654689 and parameters: {'lambda_l1': 0.6828658429096722, 'lambda_l2': 0.8917022596913275, 'num_leaves': 996, 'feature_fraction': 0.40687446010758355, 'bagging_fraction': 0.5576434847234176, 'min_child_samples': 36, 'learning_rate': 0.09008824445220467, 'n_estimators': 699}. Best is trial 10 with value: 0.9175476419808126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9166019388654689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:09:23,641] Trial 12 finished with value: 0.9166711019806039 and parameters: {'lambda_l1': 0.7476704235549295, 'lambda_l2': 0.8980392583922532, 'num_leaves': 823, 'feature_fraction': 0.4014562981232444, 'bagging_fraction': 0.5853777614743373, 'min_child_samples': 37, 'learning_rate': 0.09739195904442773, 'n_estimators': 722}. Best is trial 10 with value: 0.9175476419808126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9166711019806039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:10:59,939] Trial 13 finished with value: 0.9151659227299429 and parameters: {'lambda_l1': 0.8784371868515513, 'lambda_l2': 0.8900961562768691, 'num_leaves': 773, 'feature_fraction': 0.4038863909047579, 'bagging_fraction': 0.6056891692692756, 'min_child_samples': 39, 'learning_rate': 0.09941450502972564, 'n_estimators': 748}. Best is trial 10 with value: 0.9175476419808126.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9151659227299429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:12:47,724] Trial 14 finished with value: 0.9181956224314464 and parameters: {'lambda_l1': 0.5402558595624833, 'lambda_l2': 0.6385235992325669, 'num_leaves': 545, 'feature_fraction': 0.45869935332964945, 'bagging_fraction': 0.4052561262871234, 'min_child_samples': 34, 'learning_rate': 0.02917501960789902, 'n_estimators': 719}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9181956224314464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:14:18,592] Trial 15 finished with value: 0.917837892983839 and parameters: {'lambda_l1': 0.5209130757541505, 'lambda_l2': 0.5780248220170473, 'num_leaves': 492, 'feature_fraction': 0.4662225125541512, 'bagging_fraction': 0.426256880766853, 'min_child_samples': 33, 'learning_rate': 0.023892083477995398, 'n_estimators': 617}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.917837892983839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:15:44,674] Trial 16 finished with value: 0.9166454979437504 and parameters: {'lambda_l1': 0.4424097947991168, 'lambda_l2': 0.42933130414411264, 'num_leaves': 472, 'feature_fraction': 0.47107474360825013, 'bagging_fraction': 0.40115859826048594, 'min_child_samples': 33, 'learning_rate': 0.021257537377885775, 'n_estimators': 578}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9166454979437504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:17:16,198] Trial 17 finished with value: 0.8993131447418932 and parameters: {'lambda_l1': 0.46392751298857204, 'lambda_l2': 0.6277926413800486, 'num_leaves': 329, 'feature_fraction': 0.4732132011401762, 'bagging_fraction': 0.45746526319099645, 'min_child_samples': 42, 'learning_rate': 0.0006366430892757218, 'n_estimators': 637}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.8993131447418932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:19:57,401] Trial 18 finished with value: 0.9179457325882117 and parameters: {'lambda_l1': 0.547254640380047, 'lambda_l2': 0.44331235009702297, 'num_leaves': 600, 'feature_fraction': 0.5351243452544956, 'bagging_fraction': 0.4086948007629805, 'min_child_samples': 33, 'learning_rate': 0.025080681664170247, 'n_estimators': 823}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9179457325882117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:22:46,655] Trial 19 finished with value: 0.9154846003318908 and parameters: {'lambda_l1': 0.5669539750560105, 'lambda_l2': 0.4177906277186068, 'num_leaves': 581, 'feature_fraction': 0.5623959369201428, 'bagging_fraction': 0.47345782812077103, 'min_child_samples': 40, 'learning_rate': 0.007691211801944096, 'n_estimators': 834}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9154846003318908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:26:29,697] Trial 20 finished with value: 0.906918960879597 and parameters: {'lambda_l1': 0.38866726197681345, 'lambda_l2': 0.24298668477910815, 'num_leaves': 612, 'feature_fraction': 0.5733747733147114, 'bagging_fraction': 0.4134402403274285, 'min_child_samples': 45, 'learning_rate': 0.0013255240424677132, 'n_estimators': 964}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.906918960879597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:28:33,966] Trial 21 finished with value: 0.9164628707890433 and parameters: {'lambda_l1': 0.5528747791701618, 'lambda_l2': 0.538112967049683, 'num_leaves': 366, 'feature_fraction': 0.46819027997867513, 'bagging_fraction': 0.40651169158021466, 'min_child_samples': 33, 'learning_rate': 0.03279876969845861, 'n_estimators': 814}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9164628707890433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:31:27,928] Trial 22 finished with value: 0.9179681387065757 and parameters: {'lambda_l1': 0.5020964771952319, 'lambda_l2': 0.6810666617910582, 'num_leaves': 553, 'feature_fraction': 0.5019618603512781, 'bagging_fraction': 0.4425798372597884, 'min_child_samples': 31, 'learning_rate': 0.03137664928394416, 'n_estimators': 805}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9179681387065757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:34:14,466] Trial 23 finished with value: 0.9163446571607348 and parameters: {'lambda_l1': 0.4781469627706928, 'lambda_l2': 0.7164752598308691, 'num_leaves': 601, 'feature_fraction': 0.5191474854019219, 'bagging_fraction': 0.4526903064756712, 'min_child_samples': 31, 'learning_rate': 0.007919207112402342, 'n_estimators': 799}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9163446571607348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:37:45,308] Trial 24 finished with value: 0.9181114746150708 and parameters: {'lambda_l1': 0.605574496649715, 'lambda_l2': 0.6954079402660994, 'num_leaves': 660, 'feature_fraction': 0.505962011831695, 'bagging_fraction': 0.4882409983219047, 'min_child_samples': 35, 'learning_rate': 0.04023437051510955, 'n_estimators': 989}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9181114746150708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:41:13,832] Trial 25 finished with value: 0.9179419080904985 and parameters: {'lambda_l1': 0.8986039333356056, 'lambda_l2': 0.6877770953068493, 'num_leaves': 864, 'feature_fraction': 0.4921452687525508, 'bagging_fraction': 0.49669931350578767, 'min_child_samples': 35, 'learning_rate': 0.04353910398561978, 'n_estimators': 1000}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9179419080904985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:43:55,672] Trial 26 finished with value: 0.9177322316289366 and parameters: {'lambda_l1': 0.6177849014102984, 'lambda_l2': 0.6741942667919644, 'num_leaves': 679, 'feature_fraction': 0.447596918099547, 'bagging_fraction': 0.4865750033500183, 'min_child_samples': 39, 'learning_rate': 0.04586675236632702, 'n_estimators': 897}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9177322316289366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:46:17,094] Trial 27 finished with value: 0.9157468089591041 and parameters: {'lambda_l1': 0.4157667796135047, 'lambda_l2': 0.5201299794572127, 'num_leaves': 352, 'feature_fraction': 0.4963523052196917, 'bagging_fraction': 0.4424275002683046, 'min_child_samples': 35, 'learning_rate': 0.013609396848252877, 'n_estimators': 894}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9157468089591041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:48:34,325] Trial 28 finished with value: 0.9152450549569682 and parameters: {'lambda_l1': 0.782809627402154, 'lambda_l2': 0.662408880110879, 'num_leaves': 535, 'feature_fraction': 0.5548345041392843, 'bagging_fraction': 0.447659490225216, 'min_child_samples': 30, 'learning_rate': 0.05437636699172816, 'n_estimators': 766}. Best is trial 14 with value: 0.9181956224314464.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9152450549569682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:51:18,563] Trial 29 finished with value: 0.9197018509067505 and parameters: {'lambda_l1': 0.6571735368801115, 'lambda_l2': 0.6922642467342977, 'num_leaves': 684, 'feature_fraction': 0.44165535634643477, 'bagging_fraction': 0.4710282578369035, 'min_child_samples': 29, 'learning_rate': 0.043629507530926294, 'n_estimators': 865}. Best is trial 29 with value: 0.9197018509067505.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9197018509067505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:54:08,330] Trial 30 finished with value: 0.9183243164839363 and parameters: {'lambda_l1': 0.6237942582330259, 'lambda_l2': 0.7776622434169533, 'num_leaves': 762, 'feature_fraction': 0.4373713975733821, 'bagging_fraction': 0.5061646651615305, 'min_child_samples': 29, 'learning_rate': 0.04563114642635271, 'n_estimators': 996}. Best is trial 29 with value: 0.9197018509067505.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9183243164839363\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 21:57:04,826] Trial 31 finished with value: 0.9191059208651011 and parameters: {'lambda_l1': 0.6401696640380795, 'lambda_l2': 0.7926632577324473, 'num_leaves': 664, 'feature_fraction': 0.43560562267160147, 'bagging_fraction': 0.47087229652756785, 'min_child_samples': 29, 'learning_rate': 0.044233648709299245, 'n_estimators': 994}. Best is trial 29 with value: 0.9197018509067505.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9191059208651011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 22:00:09,467] Trial 32 finished with value: 0.9204045476836307 and parameters: {'lambda_l1': 0.741804365501437, 'lambda_l2': 0.7602122523242181, 'num_leaves': 756, 'feature_fraction': 0.4362988682280159, 'bagging_fraction': 0.4696088273288702, 'min_child_samples': 29, 'learning_rate': 0.013190378321093862, 'n_estimators': 931}. Best is trial 32 with value: 0.9204045476836307.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9204045476836307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 22:03:16,177] Trial 33 finished with value: 0.9205284537250733 and parameters: {'lambda_l1': 0.7412680496237839, 'lambda_l2': 0.7789037620801952, 'num_leaves': 774, 'feature_fraction': 0.4357395214712234, 'bagging_fraction': 0.5223357468645445, 'min_child_samples': 28, 'learning_rate': 0.014805597344181258, 'n_estimators': 937}. Best is trial 33 with value: 0.9205284537250733.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9205284537250733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 22:06:08,955] Trial 34 finished with value: 0.9211044573651911 and parameters: {'lambda_l1': 0.7296456333862358, 'lambda_l2': 0.7650090793461436, 'num_leaves': 882, 'feature_fraction': 0.43644908397209087, 'bagging_fraction': 0.4755353435998187, 'min_child_samples': 25, 'learning_rate': 0.014569923732383923, 'n_estimators': 928}. Best is trial 34 with value: 0.9211044573651911.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9211044573651911\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 22:09:08,912] Trial 35 finished with value: 0.916705294881719 and parameters: {'lambda_l1': 0.7592266622049592, 'lambda_l2': 0.5196115791278441, 'num_leaves': 891, 'feature_fraction': 0.4316372793312219, 'bagging_fraction': 0.5277518570832587, 'min_child_samples': 25, 'learning_rate': 0.0044453968924512205, 'n_estimators': 865}. Best is trial 34 with value: 0.9211044573651911.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.916705294881719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 22:12:01,232] Trial 36 finished with value: 0.9208349189432881 and parameters: {'lambda_l1': 0.7138196939873763, 'lambda_l2': 0.7728379829134736, 'num_leaves': 897, 'feature_fraction': 0.4288173751481009, 'bagging_fraction': 0.47017996137190077, 'min_child_samples': 27, 'learning_rate': 0.013220505601143785, 'n_estimators': 919}. Best is trial 34 with value: 0.9211044573651911.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9208349189432881\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 22:15:30,176] Trial 37 finished with value: 0.9205489860168916 and parameters: {'lambda_l1': 0.7943527954939018, 'lambda_l2': 0.8045243035170796, 'num_leaves': 908, 'feature_fraction': 0.4215720113754779, 'bagging_fraction': 0.5093344698855763, 'min_child_samples': 27, 'learning_rate': 0.01094425328528778, 'n_estimators': 941}. Best is trial 34 with value: 0.9211044573651911.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9205489860168916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 22:18:41,951] Trial 38 finished with value: 0.9166095996831447 and parameters: {'lambda_l1': 0.8462286411928573, 'lambda_l2': 0.822331986736999, 'num_leaves': 903, 'feature_fraction': 0.4204880487329897, 'bagging_fraction': 0.5284394586057997, 'min_child_samples': 27, 'learning_rate': 0.003993130498514124, 'n_estimators': 936}. Best is trial 34 with value: 0.9211044573651911.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9166095996831447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75408/1226370266.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n",
            "/tmp/ipykernel_75408/1226370266.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4,\n",
            "/tmp/ipykernel_75408/1226370266.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
            "/home/igvdov/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "[I 2023-11-30 22:20:19,234] Trial 39 finished with value: 0.9154305933406144 and parameters: {'lambda_l1': 0.8156473133399473, 'lambda_l2': 0.5763877416395863, 'num_leaves': 811, 'feature_fraction': 0.4246646754237079, 'bagging_fraction': 0.5124871481504083, 'min_child_samples': 25, 'learning_rate': 0.007690336103372046, 'n_estimators': 457}. Best is trial 34 with value: 0.9211044573651911.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score of LightGBM = 0.9154305933406144\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials = 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'lambda_l1': 0.7296456333862358,\n",
              " 'lambda_l2': 0.7650090793461436,\n",
              " 'num_leaves': 882,\n",
              " 'feature_fraction': 0.43644908397209087,\n",
              " 'bagging_fraction': 0.4755353435998187,\n",
              " 'min_child_samples': 25,\n",
              " 'learning_rate': 0.014569923732383923,\n",
              " 'n_estimators': 928}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tuned_params = {**study.best_params}\n",
        "tuned_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22813, number of negative: 301187\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155187 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 21991\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070410 -> initscore=-2.580401\n",
            "[LightGBM] [Info] Start training from score -2.580401\n",
            "1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22723, number of negative: 301277\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036037 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21997\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070133 -> initscore=-2.584652\n",
            "[LightGBM] [Info] Start training from score -2.584652\n",
            "2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22761, number of negative: 301239\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038853 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21989\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070250 -> initscore=-2.582855\n",
            "[LightGBM] [Info] Start training from score -2.582855\n",
            "3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22782, number of negative: 301218\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101952 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 21993\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070315 -> initscore=-2.581864\n",
            "[LightGBM] [Info] Start training from score -2.581864\n",
            "4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22730, number of negative: 301270\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096754 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 22000\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070154 -> initscore=-2.584321\n",
            "[LightGBM] [Info] Start training from score -2.584321\n",
            "5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22816, number of negative: 301184\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100668 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 21995\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070420 -> initscore=-2.580259\n",
            "[LightGBM] [Info] Start training from score -2.580259\n",
            "6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22792, number of negative: 301208\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159943 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 22003\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070346 -> initscore=-2.581391\n",
            "[LightGBM] [Info] Start training from score -2.581391\n",
            "7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22806, number of negative: 301194\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047482 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 22006\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070389 -> initscore=-2.580731\n",
            "[LightGBM] [Info] Start training from score -2.580731\n",
            "8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22807, number of negative: 301193\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155441 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 22043\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070392 -> initscore=-2.580684\n",
            "[LightGBM] [Info] Start training from score -2.580684\n",
            "9\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Info] Number of positive: 22805, number of negative: 301195\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036205 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21985\n",
            "[LightGBM] [Info] Number of data points in the train set: 324000, number of used features: 106\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.070386 -> initscore=-2.580778\n",
            "[LightGBM] [Info] Start training from score -2.580778\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedGroupKFold, KFold\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "def my_cross_valid(X, y):\n",
        "    kf = KFold(n_splits=10)\n",
        "    models = []\n",
        "    metrics = []\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    counter = 0\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        print(counter)\n",
        "        counter += 1\n",
        "  \n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        # positive_examples = np.sum(y_train)\n",
        "        # negative_examples = len(y_train) - np.sum(y_train)\n",
        "        # scale_pos_weight = (negative_examples)/(positive_examples)\n",
        "        model = LGBMClassifier(**tuned_params)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # print('score:', roc_auc_score(y_test, predicts))\n",
        "        models.append(model)\n",
        "        metrics.append(metrics)\n",
        "    return models, metrics\n",
        "models, metrics = my_cross_valid(train_df.drop(['total_target'], axis = 1), train_df.total_target)\n",
        "# predicts = []\n",
        "# probas = np.zeros(len(X_test))\n",
        "# for model in models:\n",
        "#     print(np.array(model.predict_proba(X_test)).shape)\n",
        "#     probas += model.predict_proba(X_test)[:,1] * 0.1\n",
        "    \n",
        "#     predicts.append(model.predict(X_test))\n",
        "\n",
        "\n",
        "\n",
        "# predicts = np.round(np.sum(np.array(predicts).T, axis = 1)/10)\n",
        "# print(classification_report(y_test, predicts), roc_auc_score(y_test, probas))\n",
        "# probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca4555d-2eaa-471a-82e9-a0b91f076b07",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-30T12:41:29.400353Z",
          "iopub.status.busy": "2023-08-30T12:41:29.399933Z",
          "iopub.status.idle": "2023-08-30T12:41:29.405056Z",
          "shell.execute_reply": "2023-08-30T12:41:29.404089Z",
          "shell.execute_reply.started": "2023-08-30T12:41:29.400328Z"
        },
        "id": "eca4555d-2eaa-471a-82e9-a0b91f076b07",
        "tags": []
      },
      "source": [
        "Качество получилось довольно неплохим, но его еще можно улучшить"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a209b3d4-f62c-44b2-b41b-d2cb3099891c",
      "metadata": {
        "id": "a209b3d4-f62c-44b2-b41b-d2cb3099891c"
      },
      "source": [
        "## Выгрузка результатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import catboost\n",
        "# model = catboost.CatBoostClassifier()\n",
        "# train_df[cat_cols] = train_df[cat_cols].astype(str)\n",
        "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
        "# model.fit(train_df.drop('total_target', axis = 1), train_df.total_target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b62168ec-0863-4a61-ad9b-714b3f8a06b3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:19:06.128334Z",
          "iopub.status.busy": "2023-09-06T06:19:06.127938Z",
          "iopub.status.idle": "2023-09-06T06:19:06.204306Z",
          "shell.execute_reply": "2023-09-06T06:19:06.203438Z",
          "shell.execute_reply.started": "2023-09-06T06:19:06.128309Z"
        },
        "id": "b62168ec-0863-4a61-ad9b-714b3f8a06b3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# X_test[cat_cols] = X_test[cat_cols].astype(str)\n",
        "# roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# model = LGBMClassifier()\n",
        "# model.fit(X_train, y_train)\n",
        "# roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n",
            "[LightGBM] [Warning] feature_fraction is set=0.43644908397209087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43644908397209087\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7650090793461436, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7650090793461436\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7296456333862358, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7296456333862358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4755353435998187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4755353435998187\n"
          ]
        }
      ],
      "source": [
        "predicts = []\n",
        "probas = np.zeros(len(test_df))\n",
        "for model in models:\n",
        "    # print(np.array(model.predict_proba(test_df)).shape)\n",
        "    probas += model.predict_proba(test_df.drop('id', axis = 1))[:,1] * 0.1\n",
        "    \n",
        "    predicts.append(model.predict(test_df.drop('id', axis =1 )))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_df['channel_code'] = test_df['channel_code'].apply(lambda x: 0 if x == 'НО ВКМ' or x == 'НОКМП0-350'  else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "96bee7c0-be50-4ab2-a8be-8b4c9427f31c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:19:07.031629Z",
          "iopub.status.busy": "2023-09-06T06:19:07.031235Z",
          "iopub.status.idle": "2023-09-06T06:19:07.440883Z",
          "shell.execute_reply": "2023-09-06T06:19:07.440015Z",
          "shell.execute_reply.started": "2023-09-06T06:19:07.031606Z"
        },
        "id": "96bee7c0-be50-4ab2-a8be-8b4c9427f31c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_score = probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7264130f-1cc0-4cde-a15e-1723db3bd539",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:19:07.692904Z",
          "iopub.status.busy": "2023-09-06T06:19:07.692535Z",
          "iopub.status.idle": "2023-09-06T06:19:07.715661Z",
          "shell.execute_reply": "2023-09-06T06:19:07.714864Z",
          "shell.execute_reply.started": "2023-09-06T06:19:07.692878Z"
        },
        "id": "7264130f-1cc0-4cde-a15e-1723db3bd539",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sample_submission_df = pd.read_csv(\"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "539bb73a-e850-44fd-b55a-ae335a77c19e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2023-09-06T06:19:09.478745Z",
          "iopub.status.busy": "2023-09-06T06:19:09.478373Z",
          "iopub.status.idle": "2023-09-06T06:19:09.485846Z",
          "shell.execute_reply": "2023-09-06T06:19:09.485218Z",
          "shell.execute_reply.started": "2023-09-06T06:19:09.478722Z"
        },
        "id": "539bb73a-e850-44fd-b55a-ae335a77c19e",
        "outputId": "9eec0310-62c5-4a51-8886-0f4a764db618",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360001</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360002</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360003</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>360004</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  score\n",
              "0  360000    0.5\n",
              "1  360001    0.5\n",
              "2  360002    0.5\n",
              "3  360003    0.5\n",
              "4  360004    0.5"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "43d0e500-c503-4ccd-aca5-d07d0afa5abe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:19:10.664945Z",
          "iopub.status.busy": "2023-09-06T06:19:10.664573Z",
          "iopub.status.idle": "2023-09-06T06:19:10.668598Z",
          "shell.execute_reply": "2023-09-06T06:19:10.667934Z",
          "shell.execute_reply.started": "2023-09-06T06:19:10.664920Z"
        },
        "id": "43d0e500-c503-4ccd-aca5-d07d0afa5abe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sample_submission_df[\"score\"] = test_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "0dbd4504-1f3e-401a-9bc4-40179375888d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2023-09-06T06:19:12.109339Z",
          "iopub.status.busy": "2023-09-06T06:19:12.108939Z",
          "iopub.status.idle": "2023-09-06T06:19:12.116299Z",
          "shell.execute_reply": "2023-09-06T06:19:12.115621Z",
          "shell.execute_reply.started": "2023-09-06T06:19:12.109309Z"
        },
        "id": "0dbd4504-1f3e-401a-9bc4-40179375888d",
        "outputId": "94d28eec-b06b-4db7-bf05-27dc3ffad214",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360000</td>\n",
              "      <td>0.008664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360001</td>\n",
              "      <td>0.010472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360002</td>\n",
              "      <td>0.032259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360003</td>\n",
              "      <td>0.025132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>360004</td>\n",
              "      <td>0.015269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id     score\n",
              "0  360000  0.008664\n",
              "1  360001  0.010472\n",
              "2  360002  0.032259\n",
              "3  360003  0.025132\n",
              "4  360004  0.015269"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "90f690fe-4222-41cf-9319-32f94213eb6f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-06T06:19:12.391651Z",
          "iopub.status.busy": "2023-09-06T06:19:12.391326Z",
          "iopub.status.idle": "2023-09-06T06:19:12.636773Z",
          "shell.execute_reply": "2023-09-06T06:19:12.635922Z",
          "shell.execute_reply.started": "2023-09-06T06:19:12.391628Z"
        },
        "id": "90f690fe-4222-41cf-9319-32f94213eb6f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sample_submission_df.to_csv(\"my_submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
